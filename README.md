# How do LLMs understand relevance?

This is the repository for the paper "How do LLMs understand relevance? A Mechanistic Interpretability Perspective". More instrctions on how to run the code and reproduce the results are comming soon.
